{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Archisha Sinha**\n",
        "#Domain: Natural Language Processings\n",
        "#Topic: Named Entity Recognition (NER)"
      ],
      "metadata": {
        "id": "0B4OaQP3OjzZ"
      },
      "id": "0B4OaQP3OjzZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2756b48",
      "metadata": {
        "id": "d2756b48"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5358cd2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5358cd2",
        "outputId": "5c78ca0f-105a-447c-e656-62885f28ed33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d9eecc",
      "metadata": {
        "id": "48d9eecc"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c70d9c6",
      "metadata": {
        "id": "3c70d9c6"
      },
      "source": [
        "# POS TAGGING USING NLTK"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nay3OnH2Fpan",
        "outputId": "5a8312f4-30f1-46cb-ee53-2d07e02626df"
      },
      "id": "nay3OnH2Fpan",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z1rJiNUFuKH",
        "outputId": "8dd63762-413f-418d-97b9-043e55ed7225"
      },
      "id": "9z1rJiNUFuKH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ed99f5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ed99f5e",
        "outputId": "a375a3c2-2e0c-4601-d912-f8b9b5b8cabf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK POS Tagging:\n",
            "[('A', 'DT'), ('young', 'JJ'), ('woman', 'NN'), ('named', 'VBD'), ('Priya', 'NNP'), ('was', 'VBD'), ('walking', 'VBG'), ('through', 'IN'), ('the', 'DT'), ('bustling', 'VBG'), ('streets', 'NNS'), ('of', 'IN'), ('Mumbai', 'NNP'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "sentence = \"A young woman named Priya was walking through the bustling streets of Mumbai.\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "# Print the POS tags\n",
        "print(\"NLTK POS Tagging:\")\n",
        "print(pos_tags)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53f9d012",
      "metadata": {
        "id": "53f9d012"
      },
      "source": [
        "# POS TAGGING USING SPACY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d14a63b",
      "metadata": {
        "id": "9d14a63b"
      },
      "outputs": [],
      "source": [
        "# Load the spaCy English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39974fff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39974fff",
        "outputId": "345a96ef-2798-46b9-e224-12f6212f108e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy POS Tagging:\n",
            "The DET\n",
            "quick ADJ\n",
            "brown ADJ\n",
            "fox NOUN\n",
            "jumps VERB\n",
            "over ADP\n",
            "the DET\n",
            "lazy ADJ\n",
            "dog NOUN\n",
            ". PUNCT\n"
          ]
        }
      ],
      "source": [
        "# Sample sentence\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Process the sentence with spaCy\n",
        "doc = nlp(sentence)\n",
        "\n",
        "# Extract and print the POS tags\n",
        "print(\"spaCy POS Tagging:\")\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d90fb777",
      "metadata": {
        "id": "d90fb777"
      },
      "source": [
        "# NER USING NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b21c09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6b21c09",
        "outputId": "3e3b4317-736b-40bd-9481-0ff8923b61b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK NER:\n",
            "Entity: Apple, Label: PERSON\n",
            "Entity: Inc., Label: ORGANIZATION\n",
            "Entity: Steve Jobs, Label: PERSON\n",
            "Entity: Cupertino, Label: GPE\n",
            "Entity: California, Label: GPE\n",
            "Entity: iPhone, Label: ORGANIZATION\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ],
      "source": [
        "text = \"Apple Inc. was founded by Steve Jobs in Cupertino, California. \" \\\n",
        "       \"It is known for its iPhone product line.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "# Perform NER using NLTK's named entity chunker\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "chunks = nltk.ne_chunk(pos_tags, binary=False)\n",
        "\n",
        "# Print the named entities\n",
        "print(\"NLTK NER:\")\n",
        "for chunk in chunks:\n",
        "    if isinstance(chunk, nltk.Tree):\n",
        "        entity = \" \".join([word for word, tag in chunk.leaves()])\n",
        "        label = chunk.label()\n",
        "        print(f\"Entity: {entity}, Label: {label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df62af1b",
      "metadata": {
        "id": "df62af1b"
      },
      "source": [
        "# NER USING SPACY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bbd83c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bbd83c9",
        "outputId": "39c642d1-1838-4b86-a2a3-b22b15b78ba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy NER:\n",
            "Apple Inc. ORG\n",
            "Steve Jobs PERSON\n",
            "Cupertino GPE\n",
            "California GPE\n"
          ]
        }
      ],
      "source": [
        "# Load the spaCy English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample text\n",
        "text = \"Apple Inc. was founded by Steve Jobs in Cupertino, California. \" \\\n",
        "       \"It is known for its iPhone product line.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract and print named entities and their labels\n",
        "print(\"spaCy NER:\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}